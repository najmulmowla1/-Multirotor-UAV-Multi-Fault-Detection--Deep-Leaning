{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WEEF3H0_TGS"
      },
      "outputs": [],
      "source": [
        "# ---------- CV runner: Stratified K-fold + repeated seeds ----------\n",
        "def run_stratified_cv(\n",
        "    X, y,\n",
        "    num_classes: int,\n",
        "    seeds=(42, 7, 2024),     # You can set to (42,) for faster run\n",
        "    n_splits=5,\n",
        "    epochs=200,\n",
        "    batch_size=8,\n",
        "    verbose_fit=0\n",
        "):\n",
        "    records = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        set_all_seeds(seed)\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "            # graph between folds\n",
        "            K.clear_session()\n",
        "            set_all_seeds(seed)\n",
        "\n",
        "            X_tr, X_te = X[train_idx], X[test_idx]\n",
        "            y_tr, y_te = y[train_idx], y[test_idx]\n",
        "\n",
        "            # ---- Leakage-free scaling----\n",
        "            scaler = StandardScaler()\n",
        "            X_tr = scaler.fit_transform(X_tr)\n",
        "            X_te = scaler.transform(X_te)\n",
        "\n",
        "            # ---- Reshape for CNN/LSTM branches ----\n",
        "            X_tr_r = X_tr.reshape(X_tr.shape[0], X_tr.shape[1], 1)\n",
        "            X_te_r = X_te.reshape(X_te.shape[0], X_te.shape[1], 1)\n",
        "\n",
        "            # ---- Build and train model ----\n",
        "            model = build_emhsam_cln(n_features=X_tr.shape[1], num_classes=num_classes)\n",
        "\n",
        "            callbacks = [\n",
        "                LearningRateScheduler(lr_schedule),\n",
        "\n",
        "                EarlyStopping(monitor='val_accuracy', patience=25, restore_best_weights=True)\n",
        "            ]\n",
        "\n",
        "            model.fit(\n",
        "                [X_tr_r, X_tr_r], y_tr,\n",
        "                validation_data=([X_te_r, X_te_r], y_te),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                verbose=verbose_fit,\n",
        "                callbacks=callbacks\n",
        "            )\n",
        "\n",
        "            # ---- Predict probabilities and labels ----\n",
        "            prob = model.predict([X_te_r, X_te_r], verbose=0)\n",
        "            pred = np.argmax(prob, axis=1)\n",
        "\n",
        "            # ---- Metrics ----\n",
        "            acc = accuracy_score(y_te, pred)\n",
        "            macro_p = precision_score(y_te, pred, average='macro', zero_division=0)\n",
        "            macro_r = recall_score(y_te, pred, average='macro', zero_division=0)\n",
        "            macro_f1 = f1_score(y_te, pred, average='macro', zero_division=0)\n",
        "            mcc = matthews_corrcoef(y_te, pred)\n",
        "            kappa = cohen_kappa_score(y_te, pred)\n",
        "\n",
        "            # Macro AUC (one-vs-rest)\n",
        "            try:\n",
        "                auc_macro = roc_auc_score(y_te, prob, multi_class='ovr', average='macro')\n",
        "            except ValueError:\n",
        "                auc_macro = np.nan\n",
        "\n",
        "            records.append({\n",
        "                \"seed\": seed,\n",
        "                \"fold\": fold,\n",
        "                \"acc\": acc,\n",
        "                \"macro_precision\": macro_p,\n",
        "                \"macro_recall\": macro_r,\n",
        "                \"macro_f1\": macro_f1,\n",
        "                \"mcc\": mcc,\n",
        "                \"kappa\": kappa,\n",
        "                \"auc_macro_ovr\": auc_macro\n",
        "            })\n",
        "\n",
        "            print(f\"Seed={seed} Fold={fold} | \"\n",
        "                  f\"Acc={acc:.4f} MacroF1={macro_f1:.4f} MCC={mcc:.4f} Kappa={kappa:.4f} AUC={auc_macro:.4f}\")\n",
        "\n",
        "    return pd.DataFrame.from_records(records)\n",
        "\n",
        "\n",
        "# ---------- 11) Run CV ----------\n",
        "# Adjust seeds if runtime is too high:\n",
        "#  - seeds=(42,) gives 5 runs total (5 folds)\n",
        "#  - seeds=(42,7,2024) gives 15 runs total (5 folds × 3 seeds)\n",
        "results_df = run_stratified_cv(\n",
        "    X_all, y_all,\n",
        "    num_classes=num_classes,\n",
        "    seeds=(42, 7, 2024),\n",
        "    n_splits=5,\n",
        "    epochs=200,\n",
        "    batch_size=8,\n",
        "    verbose_fit=0\n",
        ")\n",
        "\n",
        "print(\"\\n===== Fold/Seed Results =====\")\n",
        "print(results_df)\n",
        "\n",
        "\n",
        "# ---------- 12) Mean ± Std summary ----------\n",
        "metrics = [\"acc\", \"macro_precision\", \"macro_recall\", \"macro_f1\", \"mcc\", \"kappa\", \"auc_macro_ovr\"]\n",
        "\n",
        "summary = results_df[metrics].agg(['mean', 'std']).T\n",
        "summary[\"mean±std\"] = summary.apply(lambda r: f\"{r['mean']:.4f} ± {r['std']:.4f}\", axis=1)\n",
        "\n",
        "print(\"\\n===== Mean ± Std (Across all folds and seeds) =====\")\n",
        "print(summary[[\"mean±std\"]])\n",
        "\n",
        "# save for result:\n",
        "results_df.to_csv(\"emhsam_cln_cv_all_runs.csv\", index=False)\n",
        "summary.to_csv(\"emhsam_cln_cv_summary_mean_std.csv\")\n",
        "print(\"\\nSaved: emhsam_cln_cv_all_runs.csv and emhsam_cln_cv_summary_mean_std.csv\")\n"
      ]
    }
  ]
}